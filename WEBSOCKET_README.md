# üé§ WebSocket Voice Agent - Documentaci√≥n

## Descripci√≥n General

Este proyecto implementa un agente de voz que utiliza WebSockets para mantener conversaciones fluidas y naturales en tiempo real. El agente puede ejecutar herramientas de forma as√≠ncrona sin bloquear la conversaci√≥n, permitiendo una experiencia de usuario m√°s natural.

## ‚ú® Caracter√≠sticas Principales

### üîÑ Conversaci√≥n en Tiempo Real
- **WebSocket persistente**: Mantiene una conexi√≥n continua para conversaciones fluidas
- **Streaming de respuestas**: El agente responde en tiempo real, palabra por palabra
- **Estados de conversaci√≥n**: Maneja diferentes estados (idle, thinking, speaking, processing_tool)

### ‚ö° Ejecuci√≥n As√≠ncrona de Herramientas
- **Procesamiento no bloqueante**: Las herramientas se ejecutan en hilos separados
- **Notificaciones de progreso**: El usuario recibe actualizaciones sobre el estado de las herramientas
- **Manejo de errores**: Gesti√≥n robusta de errores en herramientas lentas o fallidas

### üéØ Sistema de Sesiones
- **Sesiones persistentes**: Cada conexi√≥n WebSocket mantiene su propio contexto
- **Historial de conversaci√≥n**: Se mantiene el contexto completo de la conversaci√≥n
- **Gesti√≥n autom√°tica de limpieza**: Las sesiones se limpian autom√°ticamente al desconectar

## üèóÔ∏è Arquitectura

### Componentes Principales

#### 1. `WebSocketAgentService`
**Archivo**: `app/services/websocket_agent_service.py`

Servicio principal que maneja:
- Gesti√≥n de sesiones WebSocket
- Procesamiento de mensajes
- Ejecuci√≥n as√≠ncrona de herramientas
- Streaming de respuestas de OpenAI

#### 2. `VoiceSession`
Dataclass que representa una sesi√≥n de conversaci√≥n:
```python
@dataclass
class VoiceSession:
    session_id: str
    websocket: WebSocket
    user_id: str
    state: SessionState
    conversation_history: List[Dict[str, str]]
    pending_tools: Dict[str, asyncio.Task]
    created_at: datetime
    last_activity: datetime
```

#### 3. `SessionState`
Estados posibles de una sesi√≥n:
- `IDLE`: Esperando input del usuario
- `LISTENING`: Escuchando (para futuro soporte de audio)
- `THINKING`: Procesando la respuesta
- `SPEAKING`: Enviando respuesta al usuario
- `PROCESSING_TOOL`: Ejecutando herramientas

### Rutas WebSocket

#### 4. `WebSocket Router`
**Archivo**: `app/router/routes/websocket_route.py`

- `WebSocket /ws`: Endpoint principal de WebSocket
- `GET /`: P√°gina de prueba HTML
- `GET /sessions`: Lista sesiones activas
- `GET /sessions/{session_id}`: Info de sesi√≥n espec√≠fica

## üöÄ Instalaci√≥n y Configuraci√≥n

### Dependencias Adicionales

Agrega estas dependencias a tu `requirements.ini`:

```ini
# Dependencias existentes...
fastapi==0.115.6
uvicorn==0.33.0
websockets>=12.0  # Para soporte de WebSocket
```

### Variables de Entorno

Aseg√∫rate de tener configuradas las variables de Azure OpenAI:

```bash
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

## üîß Uso

### 1. Iniciar el Servidor

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 2. Acceder a la P√°gina de Prueba

Visita: `http://localhost:8000/`

### 3. Conectar WebSocket

La p√°gina de prueba incluye un cliente JavaScript completo para probar el WebSocket.

### 4. Ejemplo de Conexi√≥n Program√°tica

```javascript
const ws = new WebSocket('ws://localhost:8000/ws');

// Primer mensaje para crear sesi√≥n
const initialMessage = {
    type: 'system',
    user_id: 'user123',
    content: ''
};
ws.send(JSON.stringify(initialMessage));

// Enviar mensaje de texto
const textMessage = {
    type: 'text',
    content: 'Hola, ¬øpuedes calcular 2+2?',
    user_id: 'user123'
};
ws.send(JSON.stringify(textMessage));
```

## üì® Protocolo de Mensajes

### Mensajes del Cliente al Servidor

#### Mensaje de Texto
```json
{
    "type": "text",
    "content": "Tu mensaje aqu√≠",
    "user_id": "identificador_usuario"
}
```

#### Mensaje de Audio (Futuro)
```json
{
    "type": "audio",
    "content": "base64_audio_data",
    "user_id": "identificador_usuario"
}
```

### Mensajes del Servidor al Cliente

#### Sesi√≥n Creada
```json
{
    "type": "session_created",
    "session_id": "uuid-session-id",
    "timestamp": "2025-07-20T10:30:00Z"
}
```

#### Mensaje del Sistema
```json
{
    "type": "system",
    "content": "Pensando en tu respuesta..."
}
```

#### Chunk de Respuesta
```json
{
    "type": "response_chunk",
    "content": "parte de la respuesta"
}
```

#### Respuesta Completa
```json
{
    "type": "response_complete",
    "content": "Respuesta completada"
}
```

#### Error
```json
{
    "type": "error",
    "content": "Descripci√≥n del error"
}
```

## üõ†Ô∏è Herramientas Disponibles

El sistema incluye varias herramientas que se ejecutan de forma as√≠ncrona:

### Herramientas B√°sicas
- `calculate`: C√°lculos matem√°ticos
- `get_current_time`: Fecha y hora actual
- `text_analysis`: An√°lisis de texto
- `get_weather_info`: Informaci√≥n del clima (placeholder)

### Herramientas de API
- `make_http_request`: Solicitudes HTTP a APIs externas
- `get_public_ip`: Obtener IP p√∫blica
- `placeholder_api_call`: Placeholder para futuras integraciones

## üéØ Flujo de Conversaci√≥n

1. **Conexi√≥n**: Cliente se conecta al WebSocket
2. **Creaci√≥n de Sesi√≥n**: Se crea una sesi√≥n √∫nica con ID
3. **Mensaje del Usuario**: Cliente env√≠a mensaje de texto
4. **Confirmaci√≥n**: Servidor confirma recepci√≥n
5. **Procesamiento**: 
   - Estado cambia a "thinking"
   - Se procesa con Azure OpenAI
   - Si se necesitan herramientas, se ejecutan as√≠ncronamente
6. **Respuesta**: 
   - Estado cambia a "speaking"
   - Respuesta se env√≠a en chunks en tiempo real
7. **Finalizaci√≥n**: Estado vuelve a "idle"

## üîç Monitoreo y Debugging

### Endpoints de Informaci√≥n

- `GET /sessions`: Ver sesiones activas
- `GET /sessions/{session_id}`: Detalles de una sesi√≥n
- `GET /agent/health`: Estado del servicio

### Logs

El sistema incluye logging detallado en:
- Creaci√≥n y cierre de sesiones
- Ejecuci√≥n de herramientas
- Errores de conexi√≥n
- Estados de conversaci√≥n

## üîÆ Futuras Implementaciones

### Soporte de Audio
- Reconocimiento de voz (Speech-to-Text)
- S√≠ntesis de voz (Text-to-Speech)
- Detecci√≥n de actividad de voz (VAD)

### Mejoras de Conversaci√≥n
- Interrupci√≥n inteligente del agente
- Detecci√≥n de contexto emocional
- Personalizaci√≥n de respuestas

### Escalabilidad
- Soporte para m√∫ltiples usuarios concurrentes
- Persistencia de sesiones en base de datos
- Balanceador de carga para WebSockets

## üêõ Soluci√≥n de Problemas

### Problemas Comunes

1. **Error de Conexi√≥n a Azure OpenAI**
   - Verificar variables de entorno
   - Usar endpoint `/agent/diagnose`

2. **WebSocket se Desconecta**
   - Verificar estabilidad de red
   - Revisar logs del servidor

3. **Herramientas Lentas**
   - Las herramientas se ejecutan as√≠ncronamente
   - El usuario recibe notificaciones de progreso

### Debug Mode

Para habilitar logs detallados, configura el nivel de logging en `config/logger_config.py`.

## üìö Referencias

- [FastAPI WebSockets](https://fastapi.tiangolo.com/advanced/websockets/)
- [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)

---

**Nota**: Este es un sistema en desarrollo. Las funcionalidades de audio se implementar√°n en futuras versiones.
